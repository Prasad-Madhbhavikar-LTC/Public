

==========
blockUpdated
==========
SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 172.19.218.45, 45863, None),broadcast_0_piece0,StorageLevel(memory, 1 replicas),35204,0))




==========
otherEvent
==========
SparkListenerDriverAccumUpdates(0,Stream((24,1), ?))




==========
jobStart
==========
SparkListenerJobStart(0,1716532480293,WrappedArray(org.apache.spark.scheduler.StageInfo@1e6c10e7),{spark.driver.port=45739, spark.master=local[*], spark.submit.pyFiles=, spark.app.startTime=1716532475259, spark.rdd.compress=True, spark.executor.id=driver, spark.app.name=pyspark-shell, spark.submit.deployMode=client, spark.driver.host=172.19.218.45, spark.app.id=local-1716532476129, spark.app.submitTime=1716532475086, spark.executor.extraJavaOptions=-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false, spark.sql.execution.id=0, spark.sql.execution.root.id=0, spark.ui.showConsoleProgress=true, spark.sql.warehouse.dir=file:/mnt/c/Users/MadhbhavikarPrasad(D/Development/data_migrator_public/spark-warehouse, spark.serializer.objectStreamReset=100, spark.driver.extraJavaOptions=-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false})




==========
stageSubmitted
==========
SparkListenerStageSubmitted(org.apache.spark.scheduler.StageInfo@78f6269e,{spark.driver.port=45739, spark.master=local[*], spark.submit.pyFiles=, spark.app.startTime=1716532475259, spark.rdd.compress=True, spark.executor.id=driver, spark.app.name=pyspark-shell, spark.submit.deployMode=client, spark.driver.host=172.19.218.45, spark.app.id=local-1716532476129, spark.app.submitTime=1716532475086, spark.executor.extraJavaOptions=-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false, spark.sql.execution.id=0, spark.sql.execution.root.id=0, spark.ui.showConsoleProgress=true, spark.sql.warehouse.dir=file:/mnt/c/Users/MadhbhavikarPrasad(D/Development/data_migrator_public/spark-warehouse, spark.serializer.objectStreamReset=100, spark.driver.extraJavaOptions=-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false})




==========
blockUpdated
==========
SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 172.19.218.45, 45863, None),broadcast_1_piece0,StorageLevel(memory, 1 replicas),6538,0))




==========
taskStart
==========
SparkListenerTaskStart(0,0,org.apache.spark.scheduler.TaskInfo@47afc4b5)




==========
taskEnd
==========
SparkListenerTaskEnd(0,0,ResultTask,Success,org.apache.spark.scheduler.TaskInfo@47afc4b5,org.apache.spark.executor.ExecutorMetrics@5818dce8,org.apache.spark.executor.TaskMetrics@260d1424)




==========
stageCompleted
==========
SparkListenerStageCompleted(org.apache.spark.scheduler.StageInfo@78f6269e)




==========
jobEnd
==========
SparkListenerJobEnd(0,1716532480665,JobSucceeded)




==========
otherEvent
==========
SparkListenerSQLExecutionEnd(0,1716532480692,Some())




==========
blockUpdated
==========
SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 172.19.218.45, 45863, None),broadcast_2_piece0,StorageLevel(memory, 1 replicas),35204,0))




==========
blockUpdated
==========
SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 172.19.218.45, 45863, None),broadcast_1_piece0,StorageLevel(1 replicas),6538,0))




==========
jobStart
==========
SparkListenerJobStart(1,1716532480840,WrappedArray(org.apache.spark.scheduler.StageInfo@6f0614ad),{spark.driver.port=45739, spark.master=local[*], spark.submit.pyFiles=, spark.app.startTime=1716532475259, spark.rdd.scope={"id":"13","name":"aggregate"}, spark.rdd.compress=True, spark.executor.id=driver, spark.app.name=pyspark-shell, spark.submit.deployMode=client, spark.driver.host=172.19.218.45, spark.app.id=local-1716532476129, spark.app.submitTime=1716532475086, spark.executor.extraJavaOptions=-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false, spark.ui.showConsoleProgress=true, spark.sql.warehouse.dir=file:/mnt/c/Users/MadhbhavikarPrasad(D/Development/data_migrator_public/spark-warehouse, spark.serializer.objectStreamReset=100, spark.driver.extraJavaOptions=-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false, spark.rdd.scope.noOverride=true})




==========
stageSubmitted
==========
SparkListenerStageSubmitted(org.apache.spark.scheduler.StageInfo@5635ff94,{spark.driver.port=45739, spark.master=local[*], spark.submit.pyFiles=, spark.app.startTime=1716532475259, spark.rdd.scope={"id":"13","name":"aggregate"}, spark.rdd.compress=True, spark.executor.id=driver, spark.app.name=pyspark-shell, spark.submit.deployMode=client, spark.driver.host=172.19.218.45, spark.app.id=local-1716532476129, spark.app.submitTime=1716532475086, spark.executor.extraJavaOptions=-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false, spark.ui.showConsoleProgress=true, spark.sql.warehouse.dir=file:/mnt/c/Users/MadhbhavikarPrasad(D/Development/data_migrator_public/spark-warehouse, spark.serializer.objectStreamReset=100, spark.driver.extraJavaOptions=-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false, spark.rdd.scope.noOverride=true})




==========
blockUpdated
==========
SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 172.19.218.45, 45863, None),broadcast_3_piece0,StorageLevel(memory, 1 replicas),13013,0))




==========
taskStart
==========
SparkListenerTaskStart(1,0,org.apache.spark.scheduler.TaskInfo@48548626)




==========
taskEnd
==========
SparkListenerTaskEnd(1,0,ResultTask,Success,org.apache.spark.scheduler.TaskInfo@48548626,org.apache.spark.executor.ExecutorMetrics@636173c,org.apache.spark.executor.TaskMetrics@59cad82b)




==========
stageCompleted
==========
SparkListenerStageCompleted(org.apache.spark.scheduler.StageInfo@5635ff94)




==========
jobEnd
==========
SparkListenerJobEnd(1,1716532481168,JobSucceeded)




==========
executorMetricsUpdate
==========
SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map((-1,-1) -> org.apache.spark.executor.ExecutorMetrics@207a55d9))